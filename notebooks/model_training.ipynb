{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a41f4ad4",
   "metadata": {},
   "source": [
    "\n",
    " # Milestone II — Why these 3 models and how they work\n",
    "\n",
    " We keep one familiar baseline and add two models with different inductive biases so their errors are less correlated.\n",
    " The trio gives strong accuracy, calibrated probabilities (needed for UI), and robustness to noisy/misspelled text.\n",
    "\n",
    " - 3 models, 3 views of the text: word-level linear, NB bias, character-level margins.\n",
    "\n",
    " ## 1) TF-IDF + Logistic Regression (LR)\n",
    " Word n-grams + LR. Fast, smooth probabilities, interpretable features. Misses char clues; linear boundary.\n",
    "\n",
    " ## 2) TF-IDF + Complement Naive Bayes (CNB)\n",
    " Word n-grams + CNB. Strong on short/imbalanced data, trains very fast. Independence assumption limits boundary.\n",
    "\n",
    " ## 3) Char TF-IDF (3–5) + Calibrated Linear SVM\n",
    " Character n-grams capture typos/subword patterns. SVM margins are strong; calibration yields probabilities.\n",
    "\n",
    " **Safety knobs**: dynamic `min_df`, capped `max_features`, `class_weight=\"balanced\"` (LR/SVM), SVM probability calibration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40348d0",
   "metadata": {},
   "source": [
    "## === Cell 1. Imports, paths, reproducibility ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7b47bf2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: /Users/mac/Desktop/dem-web\n",
      "DATA_CSV    : /Users/mac/Desktop/dem-web/data/assignment3_II.csv\n",
      "MODEL_DIR   : /Users/mac/Desktop/dem-web/model\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json, warnings, random, re\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import joblib\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Resolve dataset no matter where the notebook runs\n",
    "NB_DIR = Path.cwd().resolve()\n",
    "CANDIDATES = [\n",
    "    NB_DIR / \"data\" / \"assignment3_II.csv\",\n",
    "    NB_DIR.parent / \"data\" / \"assignment3_II.csv\",\n",
    "    NB_DIR.parents[1] / \"data\" / \"assignment3_II.csv\",\n",
    "]\n",
    "DATA_CSV = next((p for p in CANDIDATES if p.exists()), None)\n",
    "if DATA_CSV is None:\n",
    "    raise FileNotFoundError(\"Place 'assignment3_II.csv' under project_root/data/\")\n",
    "\n",
    "PROJECT_ROOT = DATA_CSV.parent.parent\n",
    "DATA_DIR  = PROJECT_ROOT / \"data\"\n",
    "MODEL_DIR = PROJECT_ROOT / \"model\"\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "ENSEMBLE_PKL   = MODEL_DIR / \"ensemble_soft.pkl\"\n",
    "MANIFEST_JSON  = MODEL_DIR / \"manifest.json\"\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"DATA_CSV    :\", DATA_CSV)\n",
    "print(\"MODEL_DIR   :\", MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52bbb75",
   "metadata": {},
   "source": [
    "## === Cell 2. Load CSV & normalize columns ===\n",
    " - Accept either `Recommended IND` or `Recommended` as label.\n",
    " - Minimal cleaning; keep \"not/never/no\" in vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8491939b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 19662\n",
      "Label: Recommended IND | Positives: 16087\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(DATA_CSV)\n",
    "\n",
    "# Display fields (fallbacks)\n",
    "df[\"Clothes Title\"] = df.get(\"Clothes Title\", df.get(\"Title\", \"\")).fillna(\"\")\n",
    "df[\"Clothes Description\"] = df.get(\"Clothes Description\", df.get(\"Review Text\", \"\")).fillna(\"\")\n",
    "\n",
    "# Ensure required columns exist\n",
    "for c in [\n",
    "    \"Clothing ID\",\"Clothes Title\",\"Clothes Description\",\"Rating\",\n",
    "    \"Division Name\",\"Department Name\",\"Class Name\",\"Review Text\",\"Title\"\n",
    "]:\n",
    "    if c not in df.columns:\n",
    "        df[c] = \"\"\n",
    "\n",
    "# Types\n",
    "def to_int_safe(x, default=0):\n",
    "    try: return int(x)\n",
    "    except: return default\n",
    "\n",
    "df[\"Clothing ID\"] = df[\"Clothing ID\"].apply(to_int_safe)\n",
    "df[\"Rating\"]      = pd.to_numeric(df[\"Rating\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "df[\"Review Text\"] = df[\"Review Text\"].fillna(\"\").astype(str)\n",
    "df[\"Title\"]       = df[\"Title\"].fillna(\"\").astype(str)\n",
    "\n",
    "# Label column\n",
    "label_col = \"Recommended IND\" if \"Recommended IND\" in df.columns else (\n",
    "            \"Recommended\" if \"Recommended\" in df.columns else None)\n",
    "if label_col is None:\n",
    "    raise ValueError(\"No label found. Expect 'Recommended IND' or 'Recommended'.\")\n",
    "\n",
    "df[label_col] = pd.to_numeric(df[label_col], errors=\"coerce\").fillna(0).astype(int)\n",
    "df = df[(df[label_col].isin([0,1]))].copy()\n",
    "\n",
    "print(\"Rows:\", len(df))\n",
    "print(\"Label:\", label_col, \"| Positives:\", int(df[label_col].sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9961f4e9",
   "metadata": {},
   "source": [
    "## === Cell 3. Light text cleaning for modeling ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7c49b9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining samples: 19662\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z0-9\\s']\", \" \", text)\n",
    "    return re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "df[\"Review Text\"] = df[\"Review Text\"].apply(clean_text)\n",
    "df[\"Title\"]       = df[\"Title\"].apply(clean_text)\n",
    "\n",
    "mask_nonempty = df[\"Review Text\"].str.len() > 0\n",
    "df = df[mask_nonempty].copy()\n",
    "\n",
    "print(\"Remaining samples:\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c751e04",
   "metadata": {},
   "source": [
    "## === Cell 4. Build corpus & labels ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1afbed5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 19662 | Positives: 16087\n",
      "Example: i had such high hopes for this dress and really wanted it to work for me i initially ordered the petite small my usual s...\n"
     ]
    }
   ],
   "source": [
    "X = df[\"Review Text\"].tolist()\n",
    "y = df[label_col].astype(int).to_numpy()\n",
    "\n",
    "print(f\"Samples: {len(y)} | Positives: {int(y.sum())}\")\n",
    "print(\"Example:\", (X[0][:120] + \"...\") if X else \"(empty)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c1f437",
   "metadata": {},
   "source": [
    "## === Cell 5. Define the 3 pipelines ===\n",
    " - Word TF-IDF (1–3) + LR (balanced).\n",
    " - Word TF-IDF (1–3) + Complement NB.\n",
    " - Char TF-IDF (3–5) + LinearSVC (calibrated to get `predict_proba`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0a12ca7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "STOP_WORDS_KEEP_NEG = sorted(list(ENGLISH_STOP_WORDS - {\"no\", \"not\", \"never\"}))\n",
    "\n",
    "def _choose_min_df(n_docs: int) -> int:\n",
    "    # Small corpora need min_df=1 to keep enough features\n",
    "    if n_docs >= 5000: return 3\n",
    "    if n_docs >= 1000: return 2\n",
    "    return 1\n",
    "\n",
    "def make_tfidf_lr(n_docs: int, max_features: int = 40_000) -> Pipeline:\n",
    "    \"\"\"Word TF-IDF 1–3 + Logistic Regression (balanced).\"\"\"\n",
    "    return Pipeline([\n",
    "        (\"tfidf\", TfidfVectorizer(\n",
    "            ngram_range=(1, 3),\n",
    "            max_features=max_features,\n",
    "            min_df=_choose_min_df(n_docs),\n",
    "            stop_words=STOP_WORDS_KEEP_NEG\n",
    "        )),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            max_iter=2000,\n",
    "            class_weight=\"balanced\",\n",
    "            solver=\"liblinear\",\n",
    "            random_state=SEED\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "def make_tfidf_cnb(n_docs: int, max_features: int = 40_000, alpha: float = 0.5) -> Pipeline:\n",
    "    \"\"\"Word TF-IDF 1–3 + Complement NB.\"\"\"\n",
    "    return Pipeline([\n",
    "        (\"tfidf\", TfidfVectorizer(\n",
    "            ngram_range=(1, 3),\n",
    "            max_features=max_features,\n",
    "            min_df=_choose_min_df(n_docs),\n",
    "            stop_words=STOP_WORDS_KEEP_NEG\n",
    "        )),\n",
    "        (\"clf\", ComplementNB(alpha=alpha))\n",
    "    ])\n",
    "\n",
    "def make_char_svm(n_docs: int, C: float = 0.5) -> Pipeline:\n",
    "    \"\"\"Char TF-IDF 3–5 + LinearSVC (calibrated for probabilities).\"\"\"\n",
    "    vec = TfidfVectorizer(\n",
    "        analyzer=\"char_wb\",\n",
    "        ngram_range=(3, 5),\n",
    "        sublinear_tf=True,\n",
    "        min_df=2\n",
    "    )\n",
    "    svm = LinearSVC(C=C, class_weight=\"balanced\", random_state=SEED)\n",
    "    cal = CalibratedClassifierCV(svm, method=\"sigmoid\", cv=3)\n",
    "    return Pipeline([(\"vec\", vec), (\"clf\", cal)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de976572",
   "metadata": {},
   "source": [
    "## == Cell 6. Build X (corpus) and y (labels) ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "89bd9ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Cell 6] Samples kept: 19662 | Positives: 16087 | Negatives: 3575\n",
      "Example: i had such high hopes for this dress and really wanted it to work for me i initially ordered the petite small my usual s...\n"
     ]
    }
   ],
   "source": [
    "def _clean_text(s: str) -> str:\n",
    "    s = (s or \"\").lower()\n",
    "    s = re.sub(r\"[^a-z0-9\\s.,!'?-]\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "dfe = df.copy()\n",
    "dfe[\"Review Text\"] = dfe[\"Review Text\"].fillna(\"\").astype(str).map(_clean_text)\n",
    "y_all = pd.to_numeric(dfe[label_col], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "mask = (dfe[\"Review Text\"].str.len() > 0) & (y_all.isin([0, 1]))\n",
    "dfe = dfe.loc[mask].reset_index(drop=True)\n",
    "\n",
    "# Final training arrays\n",
    "X = dfe[\"Review Text\"].tolist()     # corpus (list[str])\n",
    "y = dfe[label_col].astype(int).to_numpy()\n",
    "\n",
    "print(f\"[Cell 6] Samples kept: {len(y)} | Positives: {int(y.sum())} | Negatives: {len(y) - int(y.sum())}\")\n",
    "print(\"Example:\", (X[0][:120] + \"...\") if len(X) else \"(empty)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735d4055",
   "metadata": {},
   "source": [
    "## === Cell 7. Quick CV sanity check (Acc/F1/AUC) ===\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "52344654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TFIDF+LR (1–3)]  Acc=0.879  F1=0.923  AUC=0.934\n",
      "[TFIDF+CNB (1–3)]  Acc=0.892  F1=0.935  AUC=0.929\n",
      "[Char TFIDF+SVM (3–5)]  Acc=0.892  F1=0.936  AUC=0.935\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Char TFIDF+SVM (3–5)</td>\n",
       "      <td>0.892279</td>\n",
       "      <td>0.935727</td>\n",
       "      <td>0.934982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TFIDF+LR (1–3)</td>\n",
       "      <td>0.878853</td>\n",
       "      <td>0.923357</td>\n",
       "      <td>0.934167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TFIDF+CNB (1–3)</td>\n",
       "      <td>0.892127</td>\n",
       "      <td>0.934993</td>\n",
       "      <td>0.929080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name  accuracy        f1   roc_auc\n",
       "2  Char TFIDF+SVM (3–5)  0.892279  0.935727  0.934982\n",
       "0        TFIDF+LR (1–3)  0.878853  0.923357  0.934167\n",
       "1       TFIDF+CNB (1–3)  0.892127  0.934993  0.929080"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _safe_cv(y_vec: np.ndarray, seed: int = SEED) -> StratifiedKFold:\n",
    "    min_class = int(min((y_vec == 0).sum(), (y_vec == 1).sum()))\n",
    "    n_splits = max(2, min(5, min_class))\n",
    "    return StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "def _eval_model(name: str, pipe: Pipeline, X_list, y_vec):\n",
    "    cv = _safe_cv(y_vec)\n",
    "    metrics = {}\n",
    "    for metric in (\"accuracy\", \"f1\", \"roc_auc\"):\n",
    "        metrics[metric] = cross_val_score(pipe, X_list, y_vec, cv=cv, scoring=metric).mean()\n",
    "    print(f\"[{name}]  Acc={metrics['accuracy']:.3f}  F1={metrics['f1']:.3f}  AUC={metrics['roc_auc']:.3f}\")\n",
    "    return {\"name\": name, **metrics}\n",
    "\n",
    "results = []\n",
    "results.append(_eval_model(\"TFIDF+LR (1–3)\",  make_tfidf_lr(len(X)),  X, y))\n",
    "results.append(_eval_model(\"TFIDF+CNB (1–3)\", make_tfidf_cnb(len(X)), X, y))\n",
    "results.append(_eval_model(\"Char TFIDF+SVM (3–5)\", make_char_svm(len(X)), X, y))\n",
    "\n",
    "pd.DataFrame(results).sort_values(\"roc_auc\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0278aa",
   "metadata": {},
   "source": [
    "## === Cell 8. Train on all data & export artifacts ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "95302b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved → /Users/mac/Desktop/dem-web/model/ensemble_soft.pkl\n",
      "Saved → /Users/mac/Desktop/dem-web/model/manifest.json\n"
     ]
    }
   ],
   "source": [
    "# Train base models\n",
    "mdl_lr  = make_tfidf_lr(len(X)).fit(X, y)\n",
    "mdl_cnb = make_tfidf_cnb(len(X)).fit(X, y)\n",
    "mdl_svm = make_char_svm(len(X)).fit(X, y)\n",
    "\n",
    "# Soft-voting ensemble with equal weights\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"tfidf_lr\",  mdl_lr),\n",
    "        (\"tfidf_cnb\", mdl_cnb),\n",
    "        (\"char_svm\",  mdl_svm),\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    "    weights=[1.0, 1.0, 1.0],\n",
    "    n_jobs=None\n",
    ").fit(X, y)\n",
    "\n",
    "# Save model + manifest\n",
    "joblib.dump(ensemble, ENSEMBLE_PKL)\n",
    "\n",
    "manifest = {\n",
    "    \"bundle_name\": \"VotingClassifier: LR + CNB + CharSVM (soft)\",\n",
    "    \"weights\": {\"tfidf_lr\": 1.0, \"tfidf_cnb\": 1.0, \"char_svm\": 1.0},\n",
    "    \"notes\": \"Pure sklearn object (no custom class) — fixes EnsembleBundle pickle issue.\",\n",
    "    \"word_ngram\": \"(1,3)\",\n",
    "    \"char_ngram\": \"(3,5)\",\n",
    "    \"samples\": int(len(X)),\n",
    "    \"positives\": int(y.sum()),\n",
    "    \"data_csv\": str(DATA_CSV)\n",
    "}\n",
    "with open(MANIFEST_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(manifest, f, indent=2)\n",
    "\n",
    "print(f\"Saved → {ENSEMBLE_PKL}\")\n",
    "print(f\"Saved → {MANIFEST_JSON}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdece583",
   "metadata": {},
   "source": [
    " ## ===  Quick test (same object Flask will load) ===\n",
    "Uses `predict_proba` of the VotingClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d5bb9184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT: This dress is beautiful and I love it!\n",
      "  P(positive)=0.902 → Positive ✅\n",
      "\n",
      "TEXT: This product is terrible and very uncomfortable to wear.\n",
      "  P(positive)=0.197 → Negative ❌\n",
      "\n",
      "TEXT: So difficult and itchy.\n",
      "  P(positive)=0.498 → Negative ❌\n",
      "\n",
      "TEXT: Perfect fit, high quality material.\n",
      "  P(positive)=0.792 → Positive ✅\n",
      "\n",
      "TEXT: Cheap fabric, looks awful.\n",
      "  P(positive)=0.022 → Negative ❌\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EXAMPLES = [\n",
    "    \"This dress is beautiful and I love it!\",\n",
    "    \"This product is terrible and very uncomfortable to wear.\",\n",
    "    \"So difficult and itchy.\",\n",
    "    \"Perfect fit, high quality material.\",\n",
    "    \"Cheap fabric, looks awful.\"\n",
    "]\n",
    "\n",
    "def show_preds(texts: List[str], model, thr: float = 0.5):\n",
    "    for t in texts:\n",
    "        p = float(model.predict_proba([t])[0,1])\n",
    "        label = \"Positive ✅\" if p >= thr else \"Negative ❌\"\n",
    "        print(f\"TEXT: {t}\\n  P(positive)={p:.3f} → {label}\\n\")\n",
    "\n",
    "ens = joblib.load(ENSEMBLE_PKL)  # simulate Flask runtime load\n",
    "show_preds(EXAMPLES, ens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8728b31f",
   "metadata": {},
   "source": [
    "## How Flask will use it\n",
    " - At runtime: `ens = joblib.load('model/ensemble_soft.pkl')`\n",
    " - Predict: `p = float(ens.predict_proba([user_text])[0, 1])`\n",
    " - No custom classes needed → no `EnsembleBundle` import issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "165c7902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble._voting.VotingClassifier'>\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "model = joblib.load(ENSEMBLE_PKL)\n",
    "print(type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aea2132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8237e54a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
